"""
Moteur de pr√©vision des ventes pour Stokkel
Impl√©mente les mod√®les de forecasting (Prophet, SARIMA)
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import logging
from pathlib import Path
from threading import Lock

from prophet import Prophet
from prophet.serialize import model_to_json, model_from_json
import warnings
warnings.filterwarnings('ignore')

from fastapi import HTTPException, status

from .config import settings
from .schemas import ForecastPoint
from .validators import DataValidator, ValidationError
from .cache import cache

# Exceptions personnalis√©es
class ForecastError(Exception):
    """Exception personnalis√©e pour les erreurs de pr√©vision"""
    pass

class InsufficientDataError(ForecastError):
    """Donn√©es insuffisantes"""
    pass

logger = logging.getLogger(__name__)


class ForecastEngine:
    """Moteur de pr√©vision thread-safe utilisant Prophet pour les pr√©visions probabilistes"""
    
    def __init__(self):
        self.models_dir = Path(settings.models_dir)
        self.models_dir.mkdir(exist_ok=True)
        
        # Cache thread-safe
        self.trained_models: Dict[str, Prophet] = {}
        self._cache_locks: Dict[str, Lock] = {}  # Lock par produit
        self._global_lock = Lock()  # Lock pour g√©rer les locks eux-m√™mes
    
    def _get_lock(self, product_id: str) -> Lock:
        """Obtient ou cr√©e un lock pour un produit"""
        with self._global_lock:
            if product_id not in self._cache_locks:
                self._cache_locks[product_id] = Lock()
            return self._cache_locks[product_id]
        
    def generate_forecast(
        self,
        product_id: str,
        historical_data: pd.DataFrame,
        horizon_days: int = 30
    ) -> Tuple[List[ForecastPoint], Dict]:
        """
        G√©n√®re une pr√©vision probabiliste pour un produit
        
        Args:
            product_id: Identifiant du produit
            historical_data: DataFrame avec colonnes 'ds' (date) et 'y' (quantit√©)
            horizon_days: Nombre de jours √† pr√©voir
            
        Returns:
            Tuple (liste de ForecastPoint, metadata dict)
        """
        try:
            logger.info(f"Generation prevision | product={product_id} horizon={horizon_days}j")
            
            # Validation des param√®tres
            DataValidator.validate_forecast_params(horizon_days, settings.max_forecast_horizon)
            
            # Validation des donn√©es
            is_valid, error_msg = DataValidator.validate_product_data(
                historical_data, product_id, settings.min_data_points
            )
            if not is_valid:
                raise InsufficientDataError(error_msg)
            
            # V√©rifier les valeurs nulles
            if historical_data['y'].isna().any():
                logger.warning(f"‚ö†Ô∏è Valeurs manquantes d√©tect√©es pour {product_id}, nettoyage...")
                historical_data = historical_data.dropna(subset=['y'])
            
            # V√©rifier que toutes les valeurs ne sont pas nulles
            if historical_data['y'].sum() == 0:
                raise ForecastError(
                    f"Produit {product_id}: toutes les ventes sont √† z√©ro. "
                    f"Impossible de g√©n√©rer une pr√©vision significative."
                )
            
            # Entra√Ænement ou chargement du mod√®le
            model = self._get_or_train_model(product_id, historical_data)
            
            # Cr√©ation du dataframe de dates futures
            future = model.make_future_dataframe(periods=horizon_days, freq='D')
            
            # G√©n√©ration des pr√©visions
            forecast = model.predict(future)
            
            # Extraction des pr√©visions futures uniquement
            future_forecast = forecast.tail(horizon_days)
            
            # Construction des ForecastPoints avec quantiles
            forecast_points = []
            for _, row in future_forecast.iterrows():
                # Prophet fournit yhat_lower et yhat_upper pour l'intervalle de confiance
                # On calcule les quantiles approximatifs
                yhat = max(0, row['yhat'])  # Pas de pr√©visions n√©gatives
                yhat_lower = max(0, row['yhat_lower'])
                yhat_upper = max(0, row['yhat_upper'])
                
                # Approximation des quantiles
                # P10 ‚âà valeur basse de l'intervalle
                # P50 = m√©diane (yhat)
                # P90 ‚âà valeur haute de l'intervalle
                point = ForecastPoint(
                    date=row['ds'].date(),  # Convertir en date object
                    p10=round(yhat_lower, 2),
                    p50=round(yhat, 2),
                    p90=round(yhat_upper, 2)
                )
                forecast_points.append(point)
            
            # M√©triques de qualit√©
            metadata = self._calculate_forecast_metadata(
                model, historical_data, forecast, product_id
            )
            
            logger.info(f"Pr√©vision g√©n√©r√©e avec succ√®s pour {product_id}")
            
            return forecast_points, metadata
            
        except InsufficientDataError as e:
            # Erreur utilisateur: donn√©es insuffisantes
            logger.warning(str(e))
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={
                    "error": "Donn√©es insuffisantes",
                    "message": str(e),
                    "product_id": product_id,
                    "data_points": len(historical_data),
                    "required": settings.min_data_points
                }
            )
        
        except ForecastError as e:
            # Erreur m√©tier
            logger.error(str(e))
            raise HTTPException(
                status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
                detail={
                    "error": "Impossible de g√©n√©rer la pr√©vision",
                    "message": str(e),
                    "product_id": product_id
                }
            )
        
        except Exception as e:
            # Erreur technique inattendue
            logger.error(f"‚ùå Erreur technique pour {product_id}: {str(e)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail={
                    "error": "Erreur interne du serveur",
                    "message": "Une erreur technique est survenue. Veuillez r√©essayer.",
                    "product_id": product_id,
                    "support": "Contactez le support si le probl√®me persiste"
                }
            )
    
    def _get_or_train_model(self, product_id: str, data: pd.DataFrame) -> Prophet:
        """
        R√©cup√®re un mod√®le entra√Æn√© du cache ou en entra√Æne un nouveau (thread-safe)
        
        Args:
            product_id: Identifiant du produit
            data: Donn√©es d'entra√Ænement
            
        Returns:
            Mod√®le Prophet entra√Æn√©
        """
        # V√©rification rapide sans lock
        if product_id in self.trained_models:
            logger.info(f"‚úÖ Mod√®le en cache pour {product_id}")
            return self.trained_models[product_id]
        
        # V√©rifier le cache Redis
        cache_key = f"model:{product_id}"
        cached_model = cache.get(cache_key)
        if cached_model:
            logger.info(f"üî¥ Mod√®le depuis Redis pour {product_id}")
            self.trained_models[product_id] = cached_model
            return cached_model
        
        # Obtenir le lock sp√©cifique au produit
        product_lock = self._get_lock(product_id)
        
        with product_lock:
            # Double-check apr√®s avoir acquis le lock
            if product_id in self.trained_models:
                logger.info(f"‚úÖ Mod√®le en cache (double-check) pour {product_id}")
                return self.trained_models[product_id]
            
            # V√©rifier si un mod√®le sauvegard√© existe
            model_path = self.models_dir / f"{product_id}_model.json"
            if model_path.exists():
                try:
                    with open(model_path, 'r') as f:
                        model = model_from_json(f.read())
                    self.trained_models[product_id] = model
                    logger.info(f"üìÇ Mod√®le charg√© depuis {model_path}")
                    return model
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de charger {model_path}: {e}")
            
            # Entra√Æner un nouveau mod√®le
            logger.info(f"üîÑ Entra√Ænement d'un nouveau mod√®le pour {product_id}")
            model = self._train_new_model(product_id, data)
            
            # Sauvegarder dans le cache local
            self.trained_models[product_id] = model
            
            # Sauvegarder dans le cache Redis (TTL 1 heure)
            cache.set(cache_key, model, ttl=settings.cache_ttl_seconds)
            logger.info(f"üî¥ Mod√®le sauvegard√© dans Redis pour {product_id}")
            
            return model
    
    def clear_cache(self, product_id: Optional[str] = None):
        """Nettoie le cache de mani√®re thread-safe"""
        if product_id:
            product_lock = self._get_lock(product_id)
            with product_lock:
                if product_id in self.trained_models:
                    del self.trained_models[product_id]
                # Nettoyer aussi le cache Redis
                cache_key = f"model:{product_id}"
                cache.delete(cache_key)
                logger.info(f"üóëÔ∏è Cache nettoy√© pour {product_id}")
        else:
            with self._global_lock:
                self.trained_models.clear()
                # Nettoyer tout le cache Redis
                cache.clear()
                logger.info("üóëÔ∏è Cache complet nettoy√©")
    
    def _train_new_model(self, product_id: str, data: pd.DataFrame) -> Prophet:
        """
        Entra√Æne un nouveau mod√®le Prophet
        
        Args:
            product_id: Identifiant du produit
            data: Donn√©es d'entra√Ænement (colonnes ds, y)
            
        Returns:
            Mod√®le Prophet entra√Æn√©
        """
        logger.info(f"Entra√Ænement d'un nouveau mod√®le pour {product_id}")
        
        # Configuration du mod√®le Prophet
        model = Prophet(
            interval_width=settings.prophet_interval_width,
            changepoint_prior_scale=settings.prophet_changepoint_prior_scale,
            seasonality_prior_scale=settings.prophet_seasonality_prior_scale,
            daily_seasonality=False,
            weekly_seasonality=True,
            yearly_seasonality='auto',
            seasonality_mode='multiplicative'  # Meilleur pour les ventes
        )
        
        # Entra√Ænement
        model.fit(data)
        
        # Sauvegarde du mod√®le
        self._save_model(product_id, model)
        
        # Cache
        self.trained_models[product_id] = model
        
        logger.info(f"Mod√®le entra√Æn√© et sauvegard√© pour {product_id}")
        
        return model
    
    def _save_model(self, product_id: str, model: Prophet):
        """Sauvegarde un mod√®le Prophet"""
        try:
            model_path = self.models_dir / f"{product_id}_model.json"
            with open(model_path, 'w') as f:
                f.write(model_to_json(model))
            logger.info(f"Mod√®le sauvegard√©: {model_path}")
        except Exception as e:
            logger.warning(f"Impossible de sauvegarder le mod√®le: {str(e)}")
    
    def _calculate_forecast_metadata(
        self,
        model: Prophet,
        historical_data: pd.DataFrame,
        forecast: pd.DataFrame,
        product_id: str
    ) -> Dict:
        """
        Calcule les m√©tadonn√©es et m√©triques de qualit√© de la pr√©vision
        
        Args:
            model: Mod√®le Prophet utilis√©
            historical_data: Donn√©es historiques
            forecast: Pr√©visions g√©n√©r√©es
            product_id: Identifiant du produit
            
        Returns:
            Dict contenant les m√©tadonn√©es
        """
        # Calcul du MAPE (Mean Absolute Percentage Error) sur l'historique
        historical_forecast = forecast[forecast['ds'].isin(historical_data['ds'])]
        
        if len(historical_forecast) > 0:
            actual = historical_data.set_index('ds')['y']
            predicted = historical_forecast.set_index('ds')['yhat']
            
            # Alignement des donn√©es
            common_dates = actual.index.intersection(predicted.index)
            actual_aligned = actual[common_dates]
            predicted_aligned = predicted[common_dates]
            
            # Calcul du MAPE (en √©vitant la division par z√©ro)
            mask = actual_aligned != 0
            if mask.sum() > 0:
                mape = np.mean(
                    np.abs((actual_aligned[mask] - predicted_aligned[mask]) / actual_aligned[mask])
                ) * 100
            else:
                mape = None
            
            # Calcul du MAE (Mean Absolute Error)
            mae = np.mean(np.abs(actual_aligned - predicted_aligned))
            
            # Calcul du RMSE (Root Mean Squared Error)
            rmse = np.sqrt(np.mean((actual_aligned - predicted_aligned) ** 2))
        else:
            mape, mae, rmse = None, None, None
        
        # Statistiques de base
        avg_demand = historical_data['y'].mean()
        std_demand = historical_data['y'].std()
        
        metadata = {
            'model_used': 'Prophet',
            'training_data_points': len(historical_data),
            'training_period': {
                'start': historical_data['ds'].min().strftime('%Y-%m-%d'),
                'end': historical_data['ds'].max().strftime('%Y-%m-%d')
            },
            'average_daily_demand': round(avg_demand, 2),
            'demand_std_dev': round(std_demand, 2),
            'coefficient_of_variation': round(std_demand / avg_demand, 3) if avg_demand > 0 else None,
            'confidence_level': f"{int(settings.prophet_interval_width * 100)}%",
            'quality_metrics': {
                'mape': round(mape, 2) if mape is not None else 'N/A',
                'mae': round(mae, 2) if mae is not None else 'N/A',
                'rmse': round(rmse, 2) if rmse is not None else 'N/A'
            },
            'forecast_generated_at': datetime.now().isoformat()
        }
        
        return metadata
    
    def clear_cache(self, product_id: Optional[str] = None):
        """
        Nettoie le cache des mod√®les
        
        Args:
            product_id: Si sp√©cifi√©, nettoie seulement ce produit, sinon tous
        """
        if product_id:
            if product_id in self.trained_models:
                del self.trained_models[product_id]
                logger.info(f"Cache nettoy√© pour {product_id}")
        else:
            self.trained_models.clear()
            logger.info("Cache complet nettoy√©")


# Instance globale du moteur de pr√©vision
forecast_engine = ForecastEngine()